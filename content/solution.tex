\section{Lösungskonzept}
%nur das konzept WIE ich das lösen will zb. man kann wie clientid parsen mit einem WASM modul
%in der nächsten section zeige ich dann den eigentlichen code welcher dies tut

\subsection{Cluster Discovery} \label{ss:cluster-discovery}
% was ist das ? hivemq extension! what is ttl? health checks? try a connect and disconnect as health check?

HiveMQ hat mehrere Mechanismen um die individuellen Nodes zu entdecken, die in das Cluster aufgenommen werden sollen. Ein \ac{lb} muss in der Lage sein die Nodes des Clusters mit dem selben Mechanismus wie HiveMQ ausfindig zu machen. Wenn der \ac{lb} einen anderen Mechanismus benutzen würde, dann könnte der \ac{lb} eine andere Cluster Topologie als der HiveMQ Cluster bilden.\\
Envoy hat bereits mehrere Möglichkeiten Hosts eines Clusters zu entdecken:
\begin{itemize}
  \item \textbf{Static:} Alle Nodes eines Clusters werden statisch in die Envoy Konfiguration eingetragen.
  \item \textbf{Strict \ac{dns}:} Envoy löst periodisch und asynchron einen konfigurierten \ac{dns} Namen auf. Jede eingetragene \ac{ip} Adresse wird zu einem Node des Clusters. Falls ein Node entfernt wurde, werden keine neuen Clients mehr mit diesem Node verbunden werden. Mit der Variable \verb|dns_refresh_rate| kann die Frequenz, in welcher der \ac{dns} Eintrag abgefragt wird, bestimmt werden.
  \item \textbf{Logical \ac{dns}:} Ähnlich wie bei Strict \ac{dns} löst Envoy einen konfigurierten \ac{dns} Namen auf. Bei jeder neuen eingehenden Verbindung wird der \ac{dns} Name erneut aufgelöst und die erste \ac{ip} Adresse als Ziel der neuen Verbindung genommen.
  \item \textbf{Original Destination:} Envoy leitet eingehende Verbindungen anhand der \textit{Redirect Metadata} weiter. Eingehende Verbindungen müssen dafür mit einem \textit{iptables REDIRECT}, \textit{TPROXY target} oder \textit{Proxy Protocol} an Envoy weitergeleitet werden.
  \item \textbf{Endpoint Discovery Service:} Envoy ruft die Nodes eines Cluster bei einem \textit{xDS Management Server} ab. Es werden Java und Golang Bibliotheken angeboten um einen Management Server für Envoy zu programmieren und bereitzustellen. Somit ist es möglich eine komplexe Service Discovery zu implementieren.
\end{itemize}
\cite{ServiceDiscoveryEnvoy}
In Kapitel \ref{s:hivemq-cluster} wurden folgende Methoden der HiveMQ Cluster Discovery erläutert:
\begin{itemize}
  \item static
  \item multicast
  \item broadcast
  \item extension
  \item dns extension
\end{itemize}
Envoy und HiveMQ stellen beide eine statische Cluster Discovery zur Verfügung. Diese Methode ist für Cloud oder Container Umgebungen nicht optimal. Sie bietet keine Möglichkeit die Cluster Topologie dynamisch zu verändern. Container Management Umgebungen wie zum Beispiel Kubernetes erlauben dynamische Vorgänge wie das Skalieren der Replika-Sets oder Rolling-Updates. Eine statische Cluster Konfiguration schlie{\ss}t diese oder ähnliche dynamische Vorgänge aus.\\
% TODO cite dynamische vorgänge in k8s
Eine weitere gemeinsame Cluster Discovery Methode ist die Strict \ac{dns} Methode. HiveMQ hat diese Methode nicht in der Standard Version eingebaut, stellt für diesen Anwendungsfall aber eine frei zugängliche Erweiterung bereit.
Bei dieser Methode werden periodisch alle Einträge zu einem gegebenen \ac{dns} Eintrag abgefragt. Alle erhaltenen Einträge werden als Nodes des Cluster anerkannt. Die Frequenz der Abfrage kann in Envoy mit der Variable \verb|dns_refresh_rate| bestimmt werden. In der HiveMQ Erweiterung ist die Einstellung der Frequenz derzeit noch nicht möglich. Ein Issue \cite{AllowConfigurationDiscovery} und ein Pull Request \cite{ExponentialBackoffGeneral} wurden bereits zu diesem Feature auf GitHub erstellt.
\\
TODO beispiel DIG command zeigen mit ip auflösung
\\
Der Quellcodeauszug \ref{code:envoy-strict-dns} zeigt eine Envoy Cluster Konfiguration, die den \ac{dns} namen \verb|example.cluster| auflöst und neue Verbindungen auf alle Einträge an den Port \verb|1883| verteilt.
\begin{figure}
    \import{gen/}{envoy-strict-dns}
    \caption{Envoy Strict \ac{dns} Konfiguration}
    \label{code:envoy-strict-dns}
\end{figure}
Die \textit{HiveMQ DNS Cluster Discovery Extension} \cite{HiveMQExtensionDNS} muss auf allen Nodes in den Ordner \verb|/opt/hivemq/extensions| kopiert werden. Der Quellcodeauszug \ref{code:hivemq-dnsdiscovery} zeigt eine Konfigurationsdatei, die im Pfad \verb|/opt/hivemq/conf/dnsdiscovery.properties| liegen muss und das Cluster aus allen Einträgen des \ac{dns} Namens \verb|example.cluster| bildet.
\begin{figure}
    \import{gen/}{dnsdiscovery}
    \caption{HiveMQ \ac{dns} Cluster Discovery Konfiguration}
    \label{code:hivemq-dnsdiscovery}
\end{figure}

\subsection{Lastverteilung HiveMQ Cluster}

In Kapitel \ref{sp:load} wurde erläutert, dass in einem HiveMQ Cluster eine ungleiche Lastverteilung durch die verschiedenen Verhaltensweisen der Clients auftreten kann.
In dem Fall, dass ein Node eine höhere Belastung als ein anderer Node aufweist, möchte man die Gewichtung der Verteilung aller neuer Clients an die Situation anpassen. Es sollen mehr Clients an den Node mit geringerer Belastung Verbunden werden.
Einen Mechanismus, der erlaubt die Gewichtung der Nodes eines Clusters anzugeben, nennt sich \textit{weighted Round-robing}.

\subsubsection{Weighted Round Robin}
Envoy hat mehrere Load Balancing Algorithmen eingebaut. Darunter befindet sich auch weighted Round-robin. Jedem Node eines Cluster wird eine Gewichtung in Form eines Integer Wertes zugeordnet. Der Wert muss grö{\ss}er als eins sein und die Werte alles Nodes addiert darf nicht grö{\ss}er als 4294967295 sein.
Um den Prozentsatz zu berechnen, wie viele Clients mit einem individuellen Node verbunden werden, teil Envoy die Gewichtung des jeweiligen Node durch die Summe der Gewichtungen aller Nodes und mulipliziert das Ergebnis mit 100.
\cite{SupportedLoadBalancers}
\\
Tabelle \ref{table:example-cluster-weight} zeigt drei Nodes mit ihren Gewichtungen und den dazu berechneten Prozentsatz aller Clients die mit diesem Node verbunden werden.

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|l|c|c|}
    \hline
    \textbf{Node} & \textbf{Gewichtung} & \textbf{Prozent Traffic} \\
    \hline
    \hline
    Node 1 & 10 & 40\% \\
    \hline
    Node 2 & 10 & 40\% \\
    \hline
    Node 3 & 5 & 20\% \\
    \hline
\end{tabular}
\caption{Nodes mit ihren Gewichtungen und berechnetem Prozensatz}
\label{table:example-cluster-weight}
\end{table}
% TODO better table caption
Der Quellcodeauszug \ref{code:envoy-cluster-weight} zeigt eine statische Envoy Konfiguration um ein Cluster aus drei Nodes zu formen mit den Gewichtungen wie in Tabelle \ref{table:example-cluster-weight} angezeigt.
\begin{figure}
    \import{gen/}{envoy-weighted-round-robin}
    \caption{Envoy weighted Round-robin Konfiguration}
    \label{code:envoy-cluster-weight}
\end{figure}
Die Problematik bei diesem Vorgehen ist, dass man die Nodes inklusiver Gewichtung statisch und manuell in der Konfigurationsdatei angeben muss.
Neben der statischen Konfigurationsdatei bietet Envoy zwei Mechanismen für eine dynamische Konfiguration an.
\begin{itemize}
  \item \textbf{Dynamisch via Dateisystem:} Envoy liest Konfigurationsdateien, die das \textit{xDS} Protokoll implementiert haben, vom Dateisystem ein. Wenn sich die Dateien auf dem Dateisystem ändern, aktualisiert Envoy automatisch seine Konfiguration.
    \cite{ConfigurationDynamicFilesystem}
  \item \textbf{Dynamisch via Control-Plane:} Envoy holt sich seine Konfiguration dynamisch von einer Control Plane ab. Eine Control Plane ist ein \ac{api} Server, der Envoy Konfigurationen an Envoy Server schickt. Um die Konfiguration an den Envoy zu schicken benutzt die Control Plane die \textit{Data-Plane API}\cite{EnvoyproxyDataplaneapi2021} von Envoy.
    \cite{ConfigurationDynamicControl}
\end{itemize}
Die dynamische Konfiguration via Dateisystem ist gut für einzelne Envoy Instanzen, da keine individuelle Control Plane programmiert werden muss. Betreibt man jedoch ein Envoy Cluster, in dem jede Envoy Instanz die selbe Konfiguration besitzt, muss man bei einer Aktualisierung der Konfiguration die neue Datei auf die Dateisysteme aller Envoys verteilen.
Für den Anwendungsfall eines Envoy Clusters ist das dynamische verteilen mit einer Control Plane besser geeignet. Jeder Envoy wird mit einer statischen Konfigurationsdatei konfiguriert, in der die Adresse der Control Plane eingetragen ist. Sobald ein Envoy startet registriert sich dieser an der Control Plane und erhält seine Konfiguration. Das Verteilen der Konfigurationsaktualisierungen an die Envoy Instanzen wird nun von der Control Plane übernommen.
\\
Quellcodeauszug \ref{code:envoy-control-plane} zeigt eine statische Konfigurationsdatei um sich bei einer Control Plane zu registrieren die unter \verb|example.control.plane:18000| erreichbar ist.
\begin{figure}
    \import{gen/}{envoy-control-plane}
    \caption{Statische Envoy Konfiguration um sich zu einer Control Plane zu verbinden}
    \label{code:envoy-control-plane}
\end{figure}
Die Konfigurationsdatei ist in drei Teile unterteilt:
\begin{itemize}
  \item \verb|node:| Identifikation der Envoy Instanz bei der Control Plane. Eine Control Plane ist in der Lage verschiedene Konfigurationen zu handhaben. Durch \verb|node.id| kann die Envoy Instanz einer Konfiguration zugeordnet werden.
  \item \verb|dynamic_resources:| Gibt die Quelle der dynamischen Provisionierung an. Im Beispiel \ref{code:envoy-control-plane} wird eine \verb|GRPC| \ac{api} Namens \verb|xds_cluster| verwendet.
  \item \verb|static_resources:| Es wird die Quelle für eine dynamische Provisionierung definiert. Im Beispiel \ref{code:envoy-control-plane} wird eine Quelle Namens \verb|xds_cluster| definiert. Diese Quelle wird in \verb|dynamic_resources| referenziert.
\end{itemize}
Eine Control Plane kann in jeder Programmiersprache entwickelt werden und muss nur die Spezifikationen der Data-Plane API \cite{EnvoyproxyDataplaneapi2021} berücksichtigen. Um den Einstieg für Entwickler zu erleichtern stellt Envoy Bibliotheken für Java und Golang bereit. Diese abstrahieren die Implementierung der Data-Plane API.
\\
Um die Skalierung der Envoy Instanzen zu ermöglichen wird im Rahmen der Thesis eine dynamische Konfiguration via Control Plane in Golang entwickelt. Der Grund für die Auswahl der Programmiersprache ist eine persönliche Präferenz. Wie erläutert, hat diese keine Auswirkung auf das Load Balancing des Envoys.

\subsubsection{Control Plane}
Envoy stellt eine Beispiels Control Plane \cite{DynamicConfigurationControl} bereit, die als Starthilfe für eine anwendungsspezifische Control Plane dient. Für den Anwedungsfall \ac{mqtt} soll die Control Plane eine Konfiguration ähnlich dem Beispiel \ref{code:envoy-weighted-round-robin} erzeugen. Dabei werden die Nodes und deren Gewichtung von der Control Plane bestimmt.
\\
Die in Kapitel \ref{ss:cluster-discovery} beschriebene HiveMQ Cluster Discovery kann zusammen mit einem gewichtenen Round-robin nicht implementiert werden. Wenn man den einzelnen Envoy Instanzen die Ermittlung der HiveMQ Nodes überlässt, hat man in der Control Plane keine Möglichkeit diesen HiveMQ Nodes individuelle Gewichtungen zu geben. Daher muss die Cluster Discovery in der Control Plane implementiert werden. Dem Envoy werden dann explizit alle HiveMQ Node \ac{ip} Adressen mit deren Gewichtungen und Port vermittelt.

\subsubsection{DNS Cluster Discovery}
Die Implementierung der HiveMQ Cluster Discovery in der Control Plane muss sich Konzeptuell der \ac{dns} Cluster Discovery von der HiveMQ Erweiterung anlehnen. Wie schon in Kapitel \ref{ss:cluster-discovery} beschrieben würde sonst die Topolgie des HiveMQ Clusters im Envoy mit der tatsächlichen Topologie divergieren.
Die Control Plane muss asynchron und periodisch einen gegebenen Domain Namen auflösen und alle hinterlegten \ac{ip} Adressen als Nodes eines HiveMQ Clusters eintragen. Das Interval der periodischen Auflösung sollte sehr gering gehalten werden, zum Beispiel fünf Sekunden, um auf Topologie Änderungen schnell zu reagieren. In der Regel sind in gro{\ss}en Infrastrukturen eigene \ac{dns} Server installiert, die eine hohe Abfragerate verarbeiten können.
Quellcodeauszug \ref{code:dns-resolve-net} zeige die Auflösung aller \ac{ip} Adressen eines Domain Namens in Golang mit der Standard \verb|net| Bibliothek.
\begin{figure}
    \import{gen/}{dns-resolve-net}
    \caption{\ac{ip} Adressen Auflösung eines Domain Namens in Golang}
    \label{code:dns-resolve-net}
\end{figure}

\subsubsection{HiveMQ Metriken}
Um HiveMQ Nodes zu Gewichten müssen Metriken erarbeitet werden, die einen Indikator für die Auslastung des Nodes sind. Ein HiveMQ Broker stellt seine Metriken über folgende Schnittstellen bereit:
\begin{itemize}
  \item Prometheus
  \item InfluxDB
  \item Java Management Extension
\end{itemize}
\cite{MonitoringHiveMQDocumentation}
Für Golang gibt es eine Bibliothek, die es ermöglicht Prometheus Metriken zu parsen. Grafana bietet zudem eine Anbindung für Prometheus um Metriken zu Visualisieren.\\
Um das Monitoring von HiveMQ via Prometheus zu aktivieren, muss die \textit{Prometheus Monitoring Extension} \cite{HiveMQExtensionPrometheus} installiert werden. Um die Erweiterung zu konfigurieren kann eine Datei Namens \verb|/opt/hivemq/conf/prometheusConfiguration.properties| erstellt werden. Quellcodeauszug \ref{code:hivemq-prometheus-extension} zeigt eine Beispielskonfiguration.
\begin{figure}
    \import{gen/}{hivemq-prometheus-extension}
    \caption{Beispielskonfiguration für die HiveMQ Prometheus Metriken Erweiterung}
    \label{code:hivemq-prometheus-extension}
\end{figure}
Wie in Kapitel \ref{sb:overload-protection} erläutert, hat HiveMQ einen eingebauten Überlastschutz. Der aktuelle Status des Überlastschutzes kann auch über die Metriken abgefragt werden. HiveMQ stellt zudem auch noch Metriken des Host Systems, wie zum Beispiel die aktuelle \ac{cpu} Auslastung, und viele weitere Metriken bereit. Eine Liste aller Metriken findet sich in der HiveMQ Dokumentation \cite{MonitoringHiveMQDocumentation}. Tabelle \ref{table:overload-protection-metrics} gibt eine Übersicht der Metriken, die eine aktuelle Auslastung des Brokers widerspiegeln. Alle Metriken, die sich auf Clients beziehen, beinhalten nur die Daten der Clients, die auf diesem Node verbunden sind. Die Relevanz dieser Metriken für die Erstellung der Gewichtung eines Nodes wird in den Folgekapiteln untersucht.
\cite{ClusterOverloadProtection}
\begin{table}[htbp]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabularx}{\textwidth}{|p{5cm}|X|}
    \hline
    \textbf{Metrik} & \textbf{Beschreibung} \\
    \hline
    \hline
    \verb|com.hivemq.supervision.| \verb|overload.protection.level| & Aktueller \textit{Overload Protection Level} zwischen 1 und 10 \\
    \hline
    \verb|com.hivemq.overload-| \verb|protection.credits.| \verb|per-tick| & Anzahl der Credits, die ein Client alle 200 Millisekunden erhält \\
    \hline
    \verb|com.hivemq.overload-| \verb|protection.clients.| \verb|average-credits| & Durchschnittliche Anzahl der Credits aller Clients \\
    \hline
    \verb|com.hivemq.overload-| \verb|protection.clients.| \verb|using-credits| & Anzahl der Clients, die weniger als 50.000 Credits haben \\
    \hline
    \verb|com.hivemq.overload-| \verb|protection.clients.| \verb|backpressure-active| & Anzahl der Clients, die durch eine Overload Protection \ac{tcp} Backpressure haben \\
    \hline
    \verb|com.hivemq.overload-| \verb|protection.global.tasks| & Anzahl der ausstehenden Aufgaben \\
    \hline
    \verb|com.hivemq.system.os.| \verb|global.cpu.total.total| & \ac{cpu} Auslastung \\
    \hline
\end{tabularx}
\caption{HiveMQ Metriken, die eine Auskunft über die Auslastung des Brokers geben}
\label{table:overload-protection-metrics}
\end{table}

\subsubsection{Test Szenario}

\subsubsection{Overload Protection}
\subsubsection{Client Credits}
\subsubsection{Global Tasks}

\subsubsection{Health Check}
% lbendpoint health status -> can be set via control plane

\subsubsection{Aktualisierung der Konfiguration}
Um Aktualisierungen an eine Envoy Instanz zu schicken werden versionierte Momentaufnahmen (engl. \textit{Snapshots}) von einem Zustand der Konfiguration erstellt. Wenn die Version des Snapshots auf dem Envoy eine andere Version ist als die Version des aktuellen Snapshots auf der Control Plane, liefert die Control Plane den Snapshot an die Envoy Instanz aus.
Für die Entwicklung einer Control Plane bedeutet dies, sobald sich die Konfiguration ändert muss, sich auch die Version ändern, damit die neue Konfiguration an die Envoys ausgeliefert wird. Wenn die Konfiguration einen Zustand annimmt, für den sie in der Vergangenheit schon eine Version gebildet hat, sollte die Control Plane diese Version wiederverwenden. Somit kann man Snapshots mit ihrere Version in einem Cache-Speicher hinterlegen.
\\
Um bei der gleichen Cluster Konfiguration immer die selbe Version zu benutzen kann man die Cluster Konfiguration in eine Hash Funktion geben und bekommt einen String mit fixer Länge als Rückgabewert zurück. Die Hash Funktion garantiert einen immer gleichen Rückgabewert bei gleichem Input.
% TODO hash beschreiben
Die Eingabe der Hash Funktion sind alle Informationen bei deren Änderung eine neue Version erstellt werden soll. Dies ist eine Liste aller HiveMQ Nodes mit folgenden Werten:
\begin{itemize}
  \item \ac{ip} Adresse
  \item Port
  \item Gewichtung
  \item Status
\end{itemize}
Die Reihenfolge, in der die Nodes in der Liste vorkommen, ist von relevanz. Falls alle Nodes die selben Werte haben, sich aber die Reihenfolge der Liste geändert hat, würde die Hash Funktion einen neuen Wert zurückgeben. Daher muss sichergestellt werden, dass die Nodes immer in der gleichen Reihenfolge vorkommen. Um die Liste der Nodes zu sortieren muss überlegt werden welche Werte des Nodes als Vergleich benutzt werden. Dafür müssen Eigenschaften definiert werden, die einen Node einzigartig machen.
Es können niemals zwei HiveMQ Nodes die selbe \ac{ip} Adresse und den selben Port haben. Beide Werte als String vereint können somit miteinander verglichen werden um bei gleichbleibenden Nodes die selbe Reihenfolge in einer Liste einzuhalten.
% TODO soll man dafür ein beispiel machen?

\subsection{Sticky Session}
\subsubsection{Client Identifier}
\subsubsection{MQTT CONNECT}

\subsubsection{Hash?}
% clientid hash bestimmt das backend
%\subsubsection{Envoy WASM Network Filter}

\begin{comment}
- This is supposed to be the core of your thesis or project. Describe your work from a con-ceptual viewpoint.
- Example: In case you have developed some prototypical tool in your bachelor thesis, demonstrate how it is employed in its business context. More concrete example: Assume that your contribution is a Maven-Build-Plugin that further automates the deployment of changes to the claim handling process into production. In this case show how the plugin is integrated in the overall (continuous) integration and deployment process, which human ac-tors are involved, which external systems and so on. Elaborate on subtle edge cases you had to deal with, e.g., possible outages of external systems.
- Usedi  agramswhere appropriate. Standard notations are better than informal box-and-line-diagrams. Typical standard notations for a solution concept are
  - Business Process Modelling Notation (BPMN) or UML activity diagrams, that depict a workflow in which your tool is used
  - UML component diagrams, where your tool is represented by just a single component (without its ingredients) together with connected external systems
\end{comment}
